{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNn8Wdm/qs6Mh2MoFMg7XP/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"o-L_dCpyXGuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/自主練習/Python資料分析學習地圖')"],"metadata":{"id":"sjFlKErGjwHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hl3H037XECv"},"outputs":[],"source":["! pip install shap"]},{"cell_type":"code","source":["! pip install optuna"],"metadata":{"id":"altwz3aCXFOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install optuna-integration"],"metadata":{"id":"HyWGhyGJlbQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Feature Engineering  import\n","from sklearn.model_selection import train_test_split ,learning_curve\n","\n","# Model import\n","import xgboost as xgb\n","from xgboost import XGBClassifier ,XGBRegressor\n","\n","# Evaluate import\n","import optuna\n","import shap\n","# print the JS visualization code to the notebook\n","shap.plots.initjs()\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score ,roc_auc_score ,roc_curve ,classification_report ,confusion_matrix\n","\n","# sns.set(style=\"whitegrid\")\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.unicode.ambiguous_as_wide', True)\n","pd.set_option('display.unicode.east_asian_width', True)\n","pd.set_option(\"display.precision\", 2)\n","plt.rcParams['axes.unicode_minus'] = False # 正常顯示負號"],"metadata":{"id":"yWsrHMqIX5I_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n","\n","df # 284807 rows × 31 columns"],"metadata":{"id":"6BgWzu5AXFQm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"F4L0yE1BXFTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"kkDWIKJAYGJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop(columns =['Class'])\n","y = df['Class']"],"metadata":{"id":"vtCit_L8YGMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counts = np.bincount(y)\n","for i ,count in enumerate(counts):\n","  print(f\"Class {i} {count} instances\")"],"metadata":{"id":"kgPI1HUuY-no"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42 ,stratify=y)\n","\n","print('X_train:', X_train.shape)\n","print('X_test:', X_test.shape)\n","print('y_train:', X_train.shape)\n","print('y_test:', X_test.shape)\n","print('='*30)\n","# 查看全部資料的類別比例\n","print(pd.Series(y).value_counts(normalize=True))\n","# 查看訓練集標籤的分佈\n","print(pd.Series(y_train).value_counts(normalize=True))\n","# 查看測試集的標籤分佈\n","print(pd.Series(y_test).value_counts(normalize=True))"],"metadata":{"id":"QpXZ-ndkYGO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","print(f\"Training target statistics: {Counter(y_train)}\")\n","print(f\"Testing target statistics: {Counter(y_test)}\")"],"metadata":{"id":"KEVIZaClYGRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","  dtrain = xgb.DMatrix(X_train ,label=y_train)\n","  dtest = xgb.DMatrix(X_test, label=y_test)\n","  params = {\n","    \"verbosity\": 0,\n","    'task': 'train',\n","    \"eval_metric\": \"auc\",\n","    \"objective\": \"binary:logistic\",\n","    \"tree_method\": \"exact\",\n","    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]), # ,\"dart\" ,\"gblinear\" # optuna只接受gbtree\n","    # L2 regularization weight.\n","    \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n","    # L1 regularization weight.\n","    \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n","    # sampling ratio for training data.\n","    \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n","    # sampling according to each tree.\n","    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n","  }\n","  if params[\"booster\"] == \"gbtree\" or params[\"booster\"] == \"dart\":\n","    # maximum depth of the tree, signifies complexity of the tree.\n","    params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n","    # minimum child weight, larger the term more conservative the tree.\n","    params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n","    params[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n","    # defines how selective algorithm is.\n","    params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n","    params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n","\n","    # Additional parameters for Dart Booster\n","  if params[\"booster\"] == \"dart\":\n","    params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n","    params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n","    params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n","    params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n","\n","  bst = xgb.train(params, dtrain)\n","  preds = bst.predict(dtest)\n","  pred_labels = np.rint(preds)\n","  accuracy = accuracy_score(y_test, pred_labels)\n","  print(\"Accuracy:\", accuracy)\n","  return accuracy"],"metadata":{"id":"Yyo146gRYGUC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 最大化評估函數的返回值（例如準確率）時，應選擇 \"maximize\"\n","# 最小化評估函數的返回值（例如損失函數）時，應選擇 \"minimize\"\n","# study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\")\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=10, timeout=600)\n","\n","print(\"Number of finished trials: \", len(study.trials))\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(\"  Value: {}\".format(trial.value))\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","  print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"BjwDqjGJXFVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trial.params"],"metadata":{"id":"x4GKBDt3XFYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from optuna.visualization import plot_optimization_history\n","\n","plotly_config = {\"staticPlot\": True}\n","\n","fig = plot_optimization_history(study)\n","fig.show(config=plotly_config)"],"metadata":{"id":"8B5qT8p0askr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from optuna.visualization import plot_param_importances\n","\n","fig = plot_param_importances(study)\n","fig.show(config=plotly_config)"],"metadata":{"id":"IJOZSSgybbOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xgb_clf = xgb.XGBClassifier(**trial.params)\n","# xgb_clf.fit(X, y)\n","xgb_clf.fit(X_train, y_train)"],"metadata":{"id":"PEbLprn_asnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["explainer = shap.TreeExplainer(xgb_clf)\n","shap_values = explainer(X_train)"],"metadata":{"id":"h2scZGUBasqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"X_train shape:\", X_train.shape)\n","print(\"SHAP values shape:\", shap_values.shape)"],"metadata":{"id":"ylw5mY7mfu_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SHAP Summary Plot\n","shap.summary_plot(shap_values, X_train)"],"metadata":{"id":"RKg9R9r3fvCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bar chart of mean importance\n","shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"],"metadata":{"id":"kkONRtHGassn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Global bar plot\n","shap.plots.bar(shap_values)"],"metadata":{"id":"wJHqP4M6f2ua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_matrix(actual_val, pred_val, title=None):\n","    confusion_matrix = pd.crosstab(actual_val, pred_val,\n","                    rownames=['Actual'],\n","                    colnames=['Predicted'])\n","    plot = sns.heatmap(confusion_matrix, annot=True, fmt=',.0f')\n","    if title is not None:\n","        plot.set_title(title)\n","    plt.show()\n","\n","def evaluate_model_performance(model, X_train, X_test, y_train, y_test):\n","    # 訓練集上的模型評分\n","    y_train_pred = model.predict(X_train)\n","    train_accuracy = accuracy_score(y_train, y_train_pred)\n","    train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n","    train_classification_report = classification_report(y_train, y_train_pred)\n","\n","    print(\"Training Set Evaluation:\")\n","    print(\"Accuracy:\", train_accuracy)\n","    print(\"Confusion Matrix:\")\n","    print(train_conf_matrix)\n","    print(\"Classification Report:\")\n","    print(train_classification_report)\n","    print(\"\\n\")\n","\n","    # 測試集上的模型評分\n","    y_test_pred = model.predict(X_test)\n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","    test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n","    test_classification_report = classification_report(y_test, y_test_pred)\n","\n","    print(\"Testing Set Evaluation:\")\n","    print(\"Accuracy:\", test_accuracy)\n","    print(\"Confusion Matrix:\")\n","    print(test_conf_matrix)\n","    print(\"Classification Report:\")\n","    print(test_classification_report)\n","\n","    plot_confusion_matrix(y_test, y_test_pred, title=\"Confusion Matrix\")\n","\n","evaluate_model_performance(xgb_clf, X_train, X_test, y_train, y_test)"],"metadata":{"id":"WYUxPhXUasu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_learning_curve(estimator, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)):\n","    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, train_sizes=train_sizes, n_jobs=-1)\n","    # Calculate the mean and standard deviation of training and test scores\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","\n","    # Plot the learning curve\n","    plt.figure(figsize=(10, 6))\n","    plt.title(\"Learning Curve\")\n","    plt.xlabel(\"Training Examples\")\n","    plt.ylabel(\"Score\")\n","    plt.grid()\n","\n","    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n","\n","    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Score\")\n","    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation Score\")\n","\n","    plt.legend(loc=\"best\")\n","    plt.show()\n","    # Print additional information\n","    print(\"Train Sizes:\", train_sizes)\n","    print(\"Train Scores Mean:\", train_scores_mean)\n","    print(\"Test Scores Mean:\", test_scores_mean)\n","plot_learning_curve(xgb_clf, X_train, y_train)"],"metadata":{"id":"MJXh3zvUXFa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mQkbaSqlkSki"},"execution_count":null,"outputs":[]}]}